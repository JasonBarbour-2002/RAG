index,start,end,text
0,00:00:00:000,00:00:27:560," So, hello everyone. Welcome to the PC seminar. Today we have with us, Professor Amir Mowad  from American University of Beirut, and he'll be talking on the girth and parametrized complexity  of token sliding and token jumping. Thank you for joining us, Professor. Over to you  now.  Thank you, Prasivathai. Thank you for having me. It's a real pleasure to be here. So, alright,"
1,00:00:17:839,00:00:46:460," now.  Thank you, Prasivathai. Thank you for having me. It's a real pleasure to be here. So, alright,  let's jump right into it. So since I did not really know the audience too well, I made  the assumption that many of you maybe have not seen this area of combinatorial reconfiguration  problems. So I decided what I'm going to do is I'm going to give a gentle introduction"
2,00:00:33:400,00:01:04:340," the assumption that many of you maybe have not seen this area of combinatorial reconfiguration  problems. So I decided what I'm going to do is I'm going to give a gentle introduction  to the area just to show you how many exciting problems and open problems are there. And  then I will talk more about token jumping and token sliding, specifically what we know  about them, what we knew about them before we started working on this project, what we"
3,00:00:53:280,00:01:24:239," then I will talk more about token jumping and token sliding, specifically what we know  about them, what we knew about them before we started working on this project, what we  managed to discover, and the tons of questions that remain to be answered. Right. And it's  a really, I mean, the questions are so nice to state, so easy to state, and they are accessible  really to researchers at any level, which is one of the reasons why I enjoy working"
4,00:01:11:060,00:01:45:439," a really, I mean, the questions are so nice to state, so easy to state, and they are accessible  really to researchers at any level, which is one of the reasons why I enjoy working  on these problems. So hopefully you'll get to enjoy them too. So before I start, I should  point out that this is joint work that started back in the combinatorial reconfiguration  workshop almost two years ago. And it's joint work with Valentin Bartier, Nicolas Bousquet,"
5,00:01:31:879,00:02:10:360," point out that this is joint work that started back in the combinatorial reconfiguration  workshop almost two years ago. And it's joint work with Valentin Bartier, Nicolas Bousquet,  and Karl Lomer, who is my master's student. All right. So the outline of the talk, it's  going to be in four sections. I will give a gentle introduction to combinatorial reconfiguration  because I know many of you might not have seen such problems. Then I will talk about"
6,00:01:56:280,00:02:27:240," going to be in four sections. I will give a gentle introduction to combinatorial reconfiguration  because I know many of you might not have seen such problems. Then I will talk about  token jumping and token sliding, what we know about them in terms of classical complexity  or one-dimensional complexity. Then I'll talk about the parameterized complexity of these  two problems and what we know as of today as we speak, and what are the problems that"
7,00:02:15:680,00:02:42:719," or one-dimensional complexity. Then I'll talk about the parameterized complexity of these  two problems and what we know as of today as we speak, and what are the problems that  remain to be solved. And then the last part of the lecture is where I will put some of  the technical stuff to show you, to give you an idea about how we prove things when we  deal with such problems, and where are the difficulties, and what kind of techniques"
8,00:02:32:200,00:03:00:399," the technical stuff to show you, to give you an idea about how we prove things when we  deal with such problems, and where are the difficulties, and what kind of techniques  have been developed. So I tried to keep the technical part as light as I could so that  really, I mean, I can focus on the big picture and the questions to be asked and answered.  So if you have any questions along the way, please feel free to interrupt me either in"
9,00:02:47:679,00:03:21:840," really, I mean, I can focus on the big picture and the questions to be asked and answered.  So if you have any questions along the way, please feel free to interrupt me either in  the chat or by unmuting yourselves. So don't worry about leaving the questions till the  end. You can interrupt me whenever I say something that doesn't make sense. Hopefully, that won't  happen too often. All right. So what is combinatorial reconfiguration? So the best way, I think,"
10,00:03:08:439,00:03:41:180," end. You can interrupt me whenever I say something that doesn't make sense. Hopefully, that won't  happen too often. All right. So what is combinatorial reconfiguration? So the best way, I think,  to introduce is with a familiar example, which is one-player games. And the most common one  that we use is the 15 puzzle game. So for those of you who don't know the 15 puzzle  games, so you're given like a four by four grid, and you have one empty square. And basically,"
11,00:03:28:539,00:03:58:359," that we use is the 15 puzzle game. So for those of you who don't know the 15 puzzle  games, so you're given like a four by four grid, and you have one empty square. And basically,  you have all the remaining 15 squares are numbered from one to 15, and they come in  some ordering. And your job is to basically move the squares around so that all the numbers  become ordered. So it's by row. So they have to be ordered this way. So if you notice in"
12,00:03:45:459,00:04:18:080," some ordering. And your job is to basically move the squares around so that all the numbers  become ordered. So it's by row. So they have to be ordered this way. So if you notice in  this figure, the only problem is that 14 and 15 are reversed. But the only moves that  you're allowed to do is to basically move a number into the empty square. And basically,  you have to do a sequence of moves so that you get all of the numbers in order. And for"
13,00:04:04:480,00:04:37:520," you're allowed to do is to basically move a number into the empty square. And basically,  you have to do a sequence of moves so that you get all of the numbers in order. And for  those of you who know this game, this example that I have on the slide is actually unsolvable.  There is no way you can flip the order of 14 and 15 in this puzzle. And I have a link  here if you want to actually play the puzzle online, which is pretty fun."
14,00:04:25:720,00:04:57:439," There is no way you can flip the order of 14 and 15 in this puzzle. And I have a link  here if you want to actually play the puzzle online, which is pretty fun.  So why do I start my talk by talking about 15 puzzle? It's because it's really, I mean,  the way you solve the 15 puzzle tells you a lot about the area of combinatorial reconfiguration.  So the standard way we would think about the 15 puzzle is by looking at the state space"
15,00:04:43:960,00:05:16:120," the way you solve the 15 puzzle tells you a lot about the area of combinatorial reconfiguration.  So the standard way we would think about the 15 puzzle is by looking at the state space  or what we call the reconfiguration graph of the 15 puzzle. So what does that graph  consist of? Well, we have one vertex or one node in this graph for each possible configuration  of the puzzle. So basically, each possible configuration, so it would be a possible permutation"
16,00:05:02:459,00:05:34:439," consist of? Well, we have one vertex or one node in this graph for each possible configuration  of the puzzle. So basically, each possible configuration, so it would be a possible permutation  of the 15 numbers in addition to where you're going to put the empty square. Each one of  those will be a vertex in the graph. And now we connect two vertices in that graph whenever  one can be reached from the other by a single move. And what do we mean here by a single"
17,00:05:21:879,00:05:51:960," those will be a vertex in the graph. And now we connect two vertices in that graph whenever  one can be reached from the other by a single move. And what do we mean here by a single  move where it's basically just moving a number into the empty square. So if you look at the  top node here in this graph, there are four possibilities that you can do in one move,  which we call a reconfiguration step, which is you can move nine into the empty square,"
18,00:05:40:800,00:06:09:840," top node here in this graph, there are four possibilities that you can do in one move,  which we call a reconfiguration step, which is you can move nine into the empty square,  you can move three into the empty square, 12 or 15. And that gives us basically four  neighbors of that vertex in the graph. Okay, and we call this whole graph the reconfiguration  graph, or the state space, if you're more comfortable thinking about states, the states"
19,00:05:58:319,00:06:27:920," neighbors of that vertex in the graph. Okay, and we call this whole graph the reconfiguration  graph, or the state space, if you're more comfortable thinking about states, the states  of the game. So now given this graph, the reconfiguration graph, there are tons of very  interesting questions that you can ask about it. There are structural questions, and there  are algorithmic questions. And these are typically the types of questions that we're interested"
20,00:06:17:400,00:06:48:600," interesting questions that you can ask about it. There are structural questions, and there  are algorithmic questions. And these are typically the types of questions that we're interested  in in this area of combinatorial reconfiguration. So a couple of examples of structural questions  would be, well, the simplest one would be how big is this reconfiguration graph, right?  How many vertices or how many edges? And that's usually not a very hard question to answer"
21,00:06:36:160,00:07:08:259," would be, well, the simplest one would be how big is this reconfiguration graph, right?  How many vertices or how many edges? And that's usually not a very hard question to answer  in terms of upper and lower bounds. More interestingly, you could ask is this reconfiguration graph  connected, right? Or can I reach any state starting from any other state by a sequence  of legal moves? And as I told you before, for the 15 puzzle, the reconfiguration graph"
22,00:06:54:840,00:07:27:339," connected, right? Or can I reach any state starting from any other state by a sequence  of legal moves? And as I told you before, for the 15 puzzle, the reconfiguration graph  is definitely not connected, because there was no way to reverse 14 and 15 in the previous  example that I showed you. And you can easily prove that, by the way. So when it's not connected,  another question would be how many components does it have? Is there some sort of nice structure"
23,00:07:14:139,00:07:41:820," example that I showed you. And you can easily prove that, by the way. So when it's not connected,  another question would be how many components does it have? Is there some sort of nice structure  to the components of this graph? And then another question would be what is the diameter  of this reconfiguration graph or of each one of its components? And that's usually a very  important question to ask when you're dealing with one-player games, because this could"
24,00:07:33:260,00:08:00:580," of this reconfiguration graph or of each one of its components? And that's usually a very  important question to ask when you're dealing with one-player games, because this could  tell you what would be the worst possible shortest path to reach a target configuration  or to solve your game, to win your game, for example. And in the literature, this is sometimes  known as God's number, which would be the diameter of the reconfiguration graph. And"
25,00:07:48:860,00:08:18:939," or to solve your game, to win your game, for example. And in the literature, this is sometimes  known as God's number, which would be the diameter of the reconfiguration graph. And  these are all very interesting structural questions to ask about this reconfiguration  graph. Now, on the algorithmic side or the computational side, there's the obvious question  of if I'm given a starting state and some ending state or target state, like in the"
26,00:08:06:860,00:08:36:059," graph. Now, on the algorithmic side or the computational side, there's the obvious question  of if I'm given a starting state and some ending state or target state, like in the  case of the puzzle game, that I am given some starting state and we know what the goal  state is. So here, one decision problem would be to answer the question whether it's possible  to get to the target state, starting from some initial state that is also given to me."
27,00:08:23:779,00:08:54:620," state is. So here, one decision problem would be to answer the question whether it's possible  to get to the target state, starting from some initial state that is also given to me.  So you could decide to solve this problem either as a decision problem or as a search  problem, which would give you the actual sequence of steps that will take you from a state to  the target state. Other interesting computational problems, is it always possible to go from"
28,00:08:39:940,00:09:13:200," problem, which would give you the actual sequence of steps that will take you from a state to  the target state. Other interesting computational problems, is it always possible to go from  one configuration to any other? And this is basically also related to the structural question  about connected components. And the last question that I will mention, which is also interesting,  is how fast can you go from one configuration to another? Meaning, can you do it in at most"
29,00:08:59:460,00:09:42:280," about connected components. And the last question that I will mention, which is also interesting,  is how fast can you go from one configuration to another? Meaning, can you do it in at most  case steps? There is a question. I should wait or no? Okay. All right. So think about  all of these questions that we paused using the simple 15 puzzle game. And now we're going  to look at a lot of other possible problems where the same reconfiguration graph can be"
30,00:09:29:200,00:09:58:740, all of these questions that we paused using the simple 15 puzzle game. And now we're going  to look at a lot of other possible problems where the same reconfiguration graph can be  extracted and we can ask the same set of questions.  So all of you here are familiar with the k-SAT problem. So you're given a Boolean formula  and you want to know if you can satisfy this formula by assigning values to the variables.
31,00:09:47:039,00:10:15:920," So all of you here are familiar with the k-SAT problem. So you're given a Boolean formula  and you want to know if you can satisfy this formula by assigning values to the variables.  And we know that this is NP-complete for k greater than or equal to 3. So now how can  you transform this into a reconfiguration problem? Well, it's very simple. So now you're  given a formula and you're given two satisfying assignments. So you can think of those satisfying"
32,00:10:03:879,00:10:37:600," you transform this into a reconfiguration problem? Well, it's very simple. So now you're  given a formula and you're given two satisfying assignments. So you can think of those satisfying  assignments as bit vectors. And so now the question that you can ask is, can I go from  the first satisfying assignment S to the next one by basically flipping one bit at a time  under the condition that I remain a satisfying assignment at all times? And notice that without"
33,00:10:22:759,00:10:56:580," the first satisfying assignment S to the next one by basically flipping one bit at a time  under the condition that I remain a satisfying assignment at all times? And notice that without  this condition, the problem is trivial. So you can basically just flip the bits however  you like and reach S from T or T from S. But once you add this constraint of you should  remain a satisfying assignment, the problem becomes way more interesting. And you can"
34,00:10:44:180,00:11:16:360," you like and reach S from T or T from S. But once you add this constraint of you should  remain a satisfying assignment, the problem becomes way more interesting. And you can  think of this problem, again, as walking in the solution space of the given formula of  all the satisfying assignment of the formula F.  All right. So that's the SAT reconfiguration problem. Let's look at another example. Graph"
35,00:11:02:639,00:11:34:039," all the satisfying assignment of the formula F.  All right. So that's the SAT reconfiguration problem. Let's look at another example. Graph  coloring. We all know it. We all love it. You're given a graph and some integer k. And  you are asked whether you can properly k-color the graph G. And we know, again, that this  is NP-complete for k greater than or equal to 3. How do you transform that into a reconfiguration"
36,00:11:23:279,00:11:47:839," you are asked whether you can properly k-color the graph G. And we know, again, that this  is NP-complete for k greater than or equal to 3. How do you transform that into a reconfiguration  problem?  Well, now you're given a graph. You're given two colorings of the graph, alpha and beta.  And the question is, can you recolor alpha to get to beta? But you need to recolor one"
37,00:11:35:039,00:12:07:120," Well, now you're given a graph. You're given two colorings of the graph, alpha and beta.  And the question is, can you recolor alpha to get to beta? But you need to recolor one  vertex at a time. And you need to remain a proper k-coloring throughout. Same idea, again,  leads us to this notion of the reconfiguration space, where we are looking at the k-colorings  of the graph and how they are connected under this adjacency relation that we define, which"
38,00:11:55:639,00:12:22:200," leads us to this notion of the reconfiguration space, where we are looking at the k-colorings  of the graph and how they are connected under this adjacency relation that we define, which  is a single vertex recoloring.  The final example that I will mention, which will be basically what we will focus on in  the rest of the talk, is token placement, I call it. But as you will all guess, this"
39,00:12:12:080,00:12:38:120," The final example that I will mention, which will be basically what we will focus on in  the rest of the talk, is token placement, I call it. But as you will all guess, this  is the famous independent set problem. But we will look at it as a token placement problem,  because it will be more useful for the rest of the talk. So you're given a graph G and  an integer k. And the question is, can you place k tokens on your graph, k black tokens,"
40,00:12:27:800,00:12:51:759," because it will be more useful for the rest of the talk. So you're given a graph G and  an integer k. And the question is, can you place k tokens on your graph, k black tokens,  so that no two of these tokens share an edge?  And of course, we all know that this is an NP-complete problem. So how can you transform  this problem into a reconfiguration problem? Again, now I'm given a graph, two independent"
41,00:12:40:960,00:13:11:080," And of course, we all know that this is an NP-complete problem. So how can you transform  this problem into a reconfiguration problem? Again, now I'm given a graph, two independent  sets of the graph, each of size k. And the question is, can I go from one independent  set to the other under what rule? So here, defining the rule for independent set, how  can I go between consecutive independent sets, becomes a little bit less obvious. And there"
42,00:12:58:000,00:13:27:880," set to the other under what rule? So here, defining the rule for independent set, how  can I go between consecutive independent sets, becomes a little bit less obvious. And there  are two main strategies that people have attempted.  The first rule is what we call token jumping. So you are basically allowed to take any two  token on your graph and jump it to any other vertex on the graph, assuming that it doesn't"
43,00:13:16:519,00:13:51:080," The first rule is what we call token jumping. So you are basically allowed to take any two  token on your graph and jump it to any other vertex on the graph, assuming that it doesn't  have a token and that you maintain an independent set at all times. So for example, in this  example that I have here, it would be perfectly okay to take this token here and jump it to  this vertex here. Or I could also take this token here and jump it to this vertex here."
44,00:13:34:920,00:14:10:040," example that I have here, it would be perfectly okay to take this token here and jump it to  this vertex here. Or I could also take this token here and jump it to this vertex here.  No, actually that would violate the independence. So you can jump to any other vertex as long as  you maintain independence. And we call that the token jumping rule. The other rule is basically  token sliding. So in this case, we only allow a token to slide along edges of the graph."
45,00:13:57:720,00:14:28:840," you maintain independence. And we call that the token jumping rule. The other rule is basically  token sliding. So in this case, we only allow a token to slide along edges of the graph.  So a token can only move to an adjacent vertex, assuming of course this does not violate  independence. So now we have two different reconfiguration graphs we can think about.  We can think about the reconfiguration graph under the token jumping adjacency,"
46,00:14:19:480,00:14:46:039," independence. So now we have two different reconfiguration graphs we can think about.  We can think about the reconfiguration graph under the token jumping adjacency,  and we can think about the reconfiguration graph under the token sliding adjacency.  And we're going to talk about these two different problems, because they do actually behave quite  differently, and they produce quite interesting results. Like the difference between the two,"
47,00:14:34:519,00:15:05:079," And we're going to talk about these two different problems, because they do actually behave quite  differently, and they produce quite interesting results. Like the difference between the two,  we don't fully understand yet, but we kind of know that token sliding  can be harder than token jumping. But there's still a lot of questions to be answered.  All right, so some of you might be asking, why do we care about studying such problems? There's"
48,00:14:50:599,00:15:24:440," can be harder than token jumping. But there's still a lot of questions to be answered.  All right, so some of you might be asking, why do we care about studying such problems? There's  a lot of motivations out there. I mean, sometimes I would say you don't need motivation. They're  interesting. There's a lot of open questions that we need to answer. But you can also think  about reconfiguration problems as another way of modeling real-world algorithmic problems,"
49,00:15:13:560,00:15:41:560," interesting. There's a lot of open questions that we need to answer. But you can also think  about reconfiguration problems as another way of modeling real-world algorithmic problems,  because you usually never start from scratch. When you're trying to solve real-world problems,  you usually start from something, and you're trying to prove it, or make it better,  or change it to something more appropriate. Another very good application of studying"
50,00:15:29:880,00:15:57:000," you usually start from something, and you're trying to prove it, or make it better,  or change it to something more appropriate. Another very good application of studying  these problems is that they give you a better understanding of solution spaces,  which can be very important for other areas as well. And they have been used in statistical  physics, quantum computing, and in complexity theory, combinatorics, and robotics, and hopefully"
51,00:15:45:800,00:16:15:240," which can be very important for other areas as well. And they have been used in statistical  physics, quantum computing, and in complexity theory, combinatorics, and robotics, and hopefully  many more applications to come. But what I would tell you is that there are so many very interesting  problems that are so easy to start thinking about without having too much background, which is why  I think this is a very nice area to start working on at any level in your research career."
52,00:16:02:680,00:16:35:559," problems that are so easy to start thinking about without having too much background, which is why  I think this is a very nice area to start working on at any level in your research career.  All right. So I'll take a break here and take questions if there are any.  And then we will dive into the token jumping and token sliding problems, what we know about them  in terms of classical complexity, and what was basically the starting point for the project that"
53,00:16:23:159,00:16:58:040," And then we will dive into the token jumping and token sliding problems, what we know about them  in terms of classical complexity, and what was basically the starting point for the project that  led us to this paper. Any questions at this point?  I apologize for the small context, which I am interrupting here. So this is just to announce  for the PC301 workshop that will be happening in December end. And this will be slightly different"
54,00:16:46:040,00:17:18:519," I apologize for the small context, which I am interrupting here. So this is just to announce  for the PC301 workshop that will be happening in December end. And this will be slightly different  from the previous two workshops. First major difference, this will be online. Second is  some advanced topics will be discussed. So anyone who intends to explore somewhat more complex  topics in parameterized algorithms is invited to have a check. They can look at the website that"
55,00:17:03:800,00:17:42:039," some advanced topics will be discussed. So anyone who intends to explore somewhat more complex  topics in parameterized algorithms is invited to have a check. They can look at the website that  has been shared on the chat. And if you wish, you can register simply by filling a form that is  linked at the bottom of the web page. So just to inform you all about it, and sorry for the  interruption for person. All right. All right. So let's start talking about token jumping,"
56,00:17:24:440,00:18:00:359," linked at the bottom of the web page. So just to inform you all about it, and sorry for the  interruption for person. All right. All right. So let's start talking about token jumping,  token sliding, and a little bit about classical complexity. So I know everybody here knows about  P and NP, so I'm not going to talk about this. Some of you might not be familiar with the PSpace  class. So just a quick note, that's as much as you will need to know for this talk is that PSpace is"
57,00:17:48:119,00:18:20:200," P and NP, so I'm not going to talk about this. Some of you might not be familiar with the PSpace  class. So just a quick note, that's as much as you will need to know for this talk is that PSpace is  the set of all decision problems that can be solved using a polynomial amount of space.  And the reason why I mentioned this class, it's because many, many, many, many reconfiguration  problem actually are PSpace complete. Okay. And so what we know the standard inclusion is we know"
58,00:18:06:840,00:18:40:519," And the reason why I mentioned this class, it's because many, many, many, many reconfiguration  problem actually are PSpace complete. Okay. And so what we know the standard inclusion is we know  that P is contained in NP, which is contained in PSpace, but a very useful thing about PSpace is  that Savage proved that it's equal to NPSpace. So polynomial space and non-deterministic  polynomial space are the same class, basically. And that's extremely useful when you start to"
59,00:18:26:519,00:18:58:839," that Savage proved that it's equal to NPSpace. So polynomial space and non-deterministic  polynomial space are the same class, basically. And that's extremely useful when you start to  think about reconfiguration problems, because if you think of a reconfiguration problem where  you're given some state and you want to reach the other one, so basically you can solve that easily  in non-deterministic polynomial space, which basically implies that they are in PSpace."
60,00:18:44:440,00:19:16:359," you're given some state and you want to reach the other one, so basically you can solve that easily  in non-deterministic polynomial space, which basically implies that they are in PSpace.  But actually you can show a lot more than that. You can show that many, really many  reconfiguration problems are actually PSpace complete, which is not surprising, right?  The fact that many of these reconfiguration problems are PSpace complete is not very"
61,00:19:05:480,00:19:33:800," reconfiguration problems are actually PSpace complete, which is not surprising, right?  The fact that many of these reconfiguration problems are PSpace complete is not very  surprising, right? And them not being in NP is because they don't always have  polynomial size certificates, which also makes sense because sometimes the number of steps that  you need to take to go from one configuration to the other might very well be exponential"
62,00:19:22:920,00:19:49:559," polynomial size certificates, which also makes sense because sometimes the number of steps that  you need to take to go from one configuration to the other might very well be exponential  in the graph size. But there are also some extremely surprising results,  and these are some of the results, some of my favorite results in the area.  So for example, you all know that coloring is NP-complete even for k equals three."
63,00:19:38:840,00:20:10:119," and these are some of the results, some of my favorite results in the area.  So for example, you all know that coloring is NP-complete even for k equals three.  However, it turns out that if you try to solve the recoloring problem for k equals three,  it's actually polynomial time solvable. So if I give you two, three colorings of a graph and I ask  you, is there a path between them that recolors one vertex at a time and never is and is always"
64,00:19:57:319,00:20:27:640," it's actually polynomial time solvable. So if I give you two, three colorings of a graph and I ask  you, is there a path between them that recolors one vertex at a time and never is and is always  a valid three coloring, then this problem can be solved in polynomial time.  And the recoloring problem only becomes PSpace complete for k equal four and more,  right? So that's the first surprising result. Another very surprising result is that"
65,00:20:14:840,00:20:47:799," And the recoloring problem only becomes PSpace complete for k equal four and more,  right? So that's the first surprising result. Another very surprising result is that  as you're all FPT experts here, I know that you're all familiar with the fact that usually  when we study problems on graphs of bounded bucket width, path width, tree width,  they tend to become easier. It turns out that that's not really the case for reconfiguration"
66,00:20:34:840,00:21:04:440," when we study problems on graphs of bounded bucket width, path width, tree width,  they tend to become easier. It turns out that that's not really the case for reconfiguration  problems, at least for token sliding and jumping, which is the two problems that are related to  independent sets. It turns out that those two problems remain PSpace complete even if you have  a graph of constant tree width or path width or even bucket width. So a very, very, very simple"
67,00:20:52:200,00:21:29:080," independent sets. It turns out that those two problems remain PSpace complete even if you have  a graph of constant tree width or path width or even bucket width. So a very, very, very simple  graph structure, still the problem remains hard. All right. And finally, the last  theorem that I also like a lot shows you basically that sliding and jumping behave differently.  And it was shown that if you restrict yourself to bipartite graphs, where we know that max"
68,00:21:14:360,00:21:50:920," theorem that I also like a lot shows you basically that sliding and jumping behave differently.  And it was shown that if you restrict yourself to bipartite graphs, where we know that max  independent sets can be solved in polynomial time, if you restrict yourself to those graphs,  it turns out that token jumping is NP-complete, whereas token sliding is PSpace complete,  which is a strange difference between the behavior of those two problems."
69,00:21:34:200,00:22:14:519," it turns out that token jumping is NP-complete, whereas token sliding is PSpace complete,  which is a strange difference between the behavior of those two problems.  All right. So in fact, we know a lot more about token sliding and token jumping. These  problems have been at the heart of the area of combinatorial reconfiguration. They have been  studied so much, and we know so much about them, at least in terms of standard or classical"
70,00:22:03:079,00:22:35:079," problems have been at the heart of the area of combinatorial reconfiguration. They have been  studied so much, and we know so much about them, at least in terms of standard or classical  complexity. So some of the important results for our paper that we're going to focus on  is this result. So that's going to be the starting point of the results that we will discuss next  when we move to parameterized complexity. So the fact that token sliding and token jumping"
71,00:22:23:879,00:22:50:519," is this result. So that's going to be the starting point of the results that we will discuss next  when we move to parameterized complexity. So the fact that token sliding and token jumping  are PSpace complete and then NP-complete respectively on bipartite graphs was the  starting point of our next paper. But there are some very interesting results here that  are also worth mentioning. So for example, for even whole-field graphs, we know how to"
72,00:22:41:160,00:23:10:279," starting point of our next paper. But there are some very interesting results here that  are also worth mentioning. So for example, for even whole-field graphs, we know how to  solve token jumping in polynomial time, but the complexity of independent set even remains open  on this class of graphs. And the complexity of token sliding also remains open. So we don't know  how to check if given two independent sets, I can slide one to the other. Can you answer that"
73,00:22:57:319,00:23:28:519," on this class of graphs. And the complexity of token sliding also remains open. So we don't know  how to check if given two independent sets, I can slide one to the other. Can you answer that  question in polynomial time for even whole-free graphs? For split graphs and chordal graphs,  they also behave extremely differently, token sliding and token jumping, right? So they are  token sliding is PSpace complete on split graphs and chordal graphs while token jumping"
74,00:23:17:960,00:23:48:439," they also behave extremely differently, token sliding and token jumping, right? So they are  token sliding is PSpace complete on split graphs and chordal graphs while token jumping  is polynomial time. And that is some of the reasons why we feel that token sliding  is harder usually than token jumping, but it's not always the case.  All right. So that's it for classical complexity."
75,00:23:35:399,00:24:07:480," is harder usually than token jumping, but it's not always the case.  All right. So that's it for classical complexity.  So now let's move on to parameterized complexity. And let's basically think  about how you can parameterize those two problems, token jumping and token sliding.  So the obvious parameter would be the number of tokens, right? So one of the obvious parameters"
76,00:23:55:240,00:24:25:159," about how you can parameterize those two problems, token jumping and token sliding.  So the obvious parameter would be the number of tokens, right? So one of the obvious parameters  would be the number of tokens. And we're going to denote that by k. Another parameter would be  the length of the sequence. Like how many steps does it take to go from one independent set  to the other? You can also obviously parameterize by tree width or path width or any combination of"
77,00:24:13:799,00:24:45:880," the length of the sequence. Like how many steps does it take to go from one independent set  to the other? You can also obviously parameterize by tree width or path width or any combination of  the above. When we started working on this problem, our initial aim was to basically  study the parameterized complexity of token sliding and token jumping on bipartite graphs  using the parameter k number of tokens, right? Because remember, we saw that token sliding is"
78,00:24:33:639,00:25:05:400," study the parameterized complexity of token sliding and token jumping on bipartite graphs  using the parameter k number of tokens, right? Because remember, we saw that token sliding is  PSPACE complete on bipartite graphs and token jumping is NP complete. So we were interested  to see if basically this is going to give us W1 hardness for token sliding and FPTness for token  jumping. At least that was the initial hope. That's why we started working on this project."
79,00:24:52:040,00:25:25:160," to see if basically this is going to give us W1 hardness for token sliding and FPTness for token  jumping. At least that was the initial hope. That's why we started working on this project.  We weren't able to answer the two questions. So we were able to answer  one side of the question, which is we were able to show that on bipartite graphs, token sliding  is in fact W1 hard. So token sliding parameterized by the number of tokens"
80,00:25:10:840,00:25:45:240," one side of the question, which is we were able to show that on bipartite graphs, token sliding  is in fact W1 hard. So token sliding parameterized by the number of tokens  on bipartite graphs is W1 hard. We were not able to answer the question for token jumping.  So that is still an open question. So having answered that question and failed on the next  question, we started thinking about ways to basically simplify a little bit some of these"
81,00:25:32:920,00:26:07:799," So that is still an open question. So having answered that question and failed on the next  question, we started thinking about ways to basically simplify a little bit some of these  questions. So the next thing we asked ourselves, so there are two directions where you can try  and simplify. So the next thing we asked ourselves was, okay, so from bipartite graphs,  how can I go to other classes of graphs and see where token jumping becomes hard or easy?"
82,00:25:52:360,00:26:31:240," and simplify. So the next thing we asked ourselves was, okay, so from bipartite graphs,  how can I go to other classes of graphs and see where token jumping becomes hard or easy?  And it turned out that if you basically exclude only C4 from your graph,  because in bipartite graphs, you're excluding all odd cycles. And we started thinking about what  kinds of cycles affect the behavior of those problems? So the first question was, what about"
83,00:26:16:359,00:26:52:040," because in bipartite graphs, you're excluding all odd cycles. And we started thinking about what  kinds of cycles affect the behavior of those problems? So the first question was, what about  C4 free graphs? And it turned out that both problems remain W1 hard on C4 free graphs.  Now, if you exclude C3 and C4, it turns out that token jumping becomes FPG, has an order  k squared kernel. But for token sliding, we were not able to determine the complexity."
84,00:26:38:120,00:27:18:519," Now, if you exclude C3 and C4, it turns out that token jumping becomes FPG, has an order  k squared kernel. But for token sliding, we were not able to determine the complexity.  Now, if you go to the other side of that, so what if we enforce both bipartite tightness  as well as C4 freeness? So in that case, we were able to show that both problems became FPG.  Okay, and basically the bipartite bounded degree graphs was just a stepping stone"
85,00:27:01:240,00:27:34:599," as well as C4 freeness? So in that case, we were able to show that both problems became FPG.  Okay, and basically the bipartite bounded degree graphs was just a stepping stone  to get to the bipartite C4 free graph result.  So let me repeat that maybe slightly more clearly. So after basically answering the first  question, which was bipartite graphs, we were able to show that token sliding was W1 hard,"
86,00:27:23:240,00:27:50:599," So let me repeat that maybe slightly more clearly. So after basically answering the first  question, which was bipartite graphs, we were able to show that token sliding was W1 hard,  but we were not able to determine the complexity of token jumping.  So then we went to C4 free graphs, and we were able to show that both problems are actually W1  hard. Then if we added one more constraint, which was C3 C4 free graphs,"
87,00:27:38:599,00:28:05:240," So then we went to C4 free graphs, and we were able to show that both problems are actually W1  hard. Then if we added one more constraint, which was C3 C4 free graphs,  we got FPGness for token jumping, but it remained open for token sliding.  And on the other side of the spectrum, so if we keep bipartite and enforce the C4 freeness,  we get FPG for both problems."
88,00:27:56:440,00:28:40:839," And on the other side of the spectrum, so if we keep bipartite and enforce the C4 freeness,  we get FPG for both problems.  And as a side note, this blue result is not part of our paper. This was known prior to our paper.  So any questions about the results?  No questions. All right, cool."
89,00:28:20:440,00:29:11:560," So any questions about the results?  No questions. All right, cool.  So lots of open problems. The first and obvious one is, is token jumping FPG parameterized by  k on bipartite graphs? And that's really, I mean, that was the initial question that we set out to  answer and couldn't. So that remains open. And so I will not be going over the hardness reduction"
90,00:28:53:400,00:29:31:880," k on bipartite graphs? And that's really, I mean, that was the initial question that we set out to  answer and couldn't. So that remains open. And so I will not be going over the hardness reduction  for token sliding on bipartite graphs, because it's quite technical. I don't feel a talk is the  right place to go over it. But if you go over the reduction, you will see that the two problems  really behave differently. And there doesn't seem to be a chance to basically make the same"
91,00:29:16:920,00:29:51:480," right place to go over it. But if you go over the reduction, you will see that the two problems  really behave differently. And there doesn't seem to be a chance to basically make the same  type of reduction work for token jumping. So the second interesting open question is,  how about token jumping parameterized by k on triangle-free graphs? That's basically  even more general than question one. And the reason why I mentioned this question separately"
92,00:29:38:519,00:30:12:519," how about token jumping parameterized by k on triangle-free graphs? That's basically  even more general than question one. And the reason why I mentioned this question separately  is because almost every reduction that I know of includes large cliques. So you need to use  large cliques in your reductions. So how about if we don't allow triangles and large cliques?  So can we then say something about the problem? So that's for token jumping. Now, when you go"
93,00:29:58:360,00:30:36:039," large cliques in your reductions. So how about if we don't allow triangles and large cliques?  So can we then say something about the problem? So that's for token jumping. Now, when you go  to token sliding, so the open problem is, what happens for token sliding on graphs of girth  at least 5? So if they are C3, C4 free. Or you can even make that a bit weaker and ask for any  girth of at least p, for some constant p. And for all of these questions, of course,"
94,00:30:20:279,00:31:03:720," at least 5? So if they are C3, C4 free. Or you can even make that a bit weaker and ask for any  girth of at least p, for some constant p. And for all of these questions, of course,  polynomial kernels would be interesting as well. Because in our case, we do get polynomial kernels  for the FPT design. The polynomials are not great, but polynomial regardless.  All right. So in the rest of the talk, I will try to cover some of the technical stuff."
95,00:30:44:120,00:31:21:240," for the FPT design. The polynomials are not great, but polynomial regardless.  All right. So in the rest of the talk, I will try to cover some of the technical stuff.  And as promised, I will try to keep it as light as possible so that I can give you  some of a lot of the intuition and techniques that are used in this paper and that are generally  used when dealing with reconfiguration problems. So the first result that we will go over is this"
96,00:31:08:200,00:31:43:160," some of a lot of the intuition and techniques that are used in this paper and that are generally  used when dealing with reconfiguration problems. So the first result that we will go over is this  W hardness on C4 free graphs for both token sliding and token jumping. It's the same reduction,  and you will get both results because we will be using maximum independent sets.  So if you're trying to basically do token sliding from one maximum independent set to the other"
97,00:31:28:200,00:31:59:480," and you will get both results because we will be using maximum independent sets.  So if you're trying to basically do token sliding from one maximum independent set to the other  or token jumping, these two rules become equivalent. Jumping becomes equivalent to sliding.  So when you're dealing with maximum independent sets, these two basically rules are the same.  And that's what we're going to do. But what we're going to prove actually is a stronger"
98,00:31:49:480,00:32:22:760," So when you're dealing with maximum independent sets, these two basically rules are the same.  And that's what we're going to do. But what we're going to prove actually is a stronger  theorem. What we're going to prove is the following theorem. If you take any p greater  than or equal to 4, then both problems are W-hard on C4, C5, dot, dot, dot up to CP free graphs,  which implies, of course, C4 free graphs. But you can basically exclude"
99,00:32:04:840,00:32:49:560," than or equal to 4, then both problems are W-hard on C4, C5, dot, dot, dot up to CP free graphs,  which implies, of course, C4 free graphs. But you can basically exclude  any cycles from C4 up to CP for constant p, and the problems will remain W-hard.  So how do we prove this result? In fact, we use a known reduction  from a problem known as grid tiling, which is a W-1-hard problem. And grid tiling is reduced"
100,00:32:34:840,00:33:12:600," So how do we prove this result? In fact, we use a known reduction  from a problem known as grid tiling, which is a W-1-hard problem. And grid tiling is reduced  to the independent set problem on C4 up to CP free graphs. And that reduction was used to show  that independent set remains W-1-hard if you exclude C4 up to CP for any constant p.  But what is interesting and useful in that reduction is the graph that is obtained"
101,00:32:58:120,00:33:32:200," that independent set remains W-1-hard if you exclude C4 up to CP for any constant p.  But what is interesting and useful in that reduction is the graph that is obtained  from the reduction. So the graph that is obtained from the reduction  has three properties that are going to be useful to us. The first property is that you can partition  the graph into basically 8k squared into p plus 1 cliques. So you have a bunch of cliques,"
102,00:33:17:480,00:33:49:559," has three properties that are going to be useful to us. The first property is that you can partition  the graph into basically 8k squared into p plus 1 cliques. So you have a bunch of cliques,  each of size n, and all of the edges basically are between the cliques.  But that's it. That's it. That's the whole of the graph. It's a bunch of cliques  and edges between them. Of course, the more important property as well here is that"
103,00:33:38:919,00:34:11:239," But that's it. That's it. That's the whole of the graph. It's a bunch of cliques  and edges between them. Of course, the more important property as well here is that  this graph is going to be C4 up to CP free. It will not have any of those cycles as an  induced subgraph. And it's an equivalent instance to the grid tiling instance.  And that basically gives you W-1-hardness of independent set on this class of graphs."
104,00:33:57:159,00:34:29:080," induced subgraph. And it's an equivalent instance to the grid tiling instance.  And that basically gives you W-1-hardness of independent set on this class of graphs.  So notice in this case that an independent set of size 8k squared into p plus 1 will  have to be a maximum independent set because that's how many cliques we get in the resulting  graph. And that's basically the sizes that we will be working with, more or less up to some"
105,00:34:19:240,00:34:52:280," have to be a maximum independent set because that's how many cliques we get in the resulting  graph. And that's basically the sizes that we will be working with, more or less up to some  modifications. But this will allow us to basically conclude that both sliding and jumping are hard  on this class of graphs. So how do we use this for showing hardness of token sliding and token  jumping? And let's focus on token sliding for now because it's going to be the same anyway."
106,00:34:37:320,00:35:09:400, on this class of graphs. So how do we use this for showing hardness of token sliding and token  jumping? And let's focus on token sliding for now because it's going to be the same anyway.  So we have those cliques and some edges that go between the cliques.  So the first attempt would be as follows. We will add a universal vertex to each one of the cliques  and we will call this the starting set or the starting independent set.
107,00:34:57:960,00:35:30:199, So the first attempt would be as follows. We will add a universal vertex to each one of the cliques  and we will call this the starting set or the starting independent set.  And then we add another universal vertex to each one of the cliques and call this the target  independent set. And now basically we have our instance of token sliding. We want to slide  everybody in s down to t. So notice that this is useful because we don't introduce any of the
108,00:35:15:239,00:35:51:400," independent set. And now basically we have our instance of token sliding. We want to slide  everybody in s down to t. So notice that this is useful because we don't introduce any of the  forbidden cycles. So we are still fine. And if we could guarantee that all of the tokens will be  on the cliques simultaneously, then this will imply an independent set in the original graph,  which concludes our proof. But unfortunately, in this case, we definitely cannot conclude that"
109,00:35:38:679,00:36:14:440," on the cliques simultaneously, then this will imply an independent set in the original graph,  which concludes our proof. But unfortunately, in this case, we definitely cannot conclude that  because each red token can slide independently here and then here, and then the next one can  follow, et cetera, et cetera, et cetera. So you need some way of forbidding these tokens  to behave freely. We want to ensure that they will all be inside the cliques simultaneously"
110,00:35:59:319,00:36:35:799," follow, et cetera, et cetera, et cetera. So you need some way of forbidding these tokens  to behave freely. We want to ensure that they will all be inside the cliques simultaneously  and we will be done. And notice that we're going to have 8k squared and 2p plus one tokens, right?  One for each clique and two universal vertices for each clique. So how do we fix this simultaneity  issue? Well, here's how we can do it. So instead of simply adding universal vertices,"
111,00:36:19:799,00:36:55:000," One for each clique and two universal vertices for each clique. So how do we fix this simultaneity  issue? Well, here's how we can do it. So instead of simply adding universal vertices,  we're also going to add an edge between every two universal vertices of a clique.  And then we're going to add something that we call a switch. And in this case, it's a simple edge.  And the red token here needs to go to the blue position, right? So now we have one extra"
112,00:36:41:640,00:37:17:720," And then we're going to add something that we call a switch. And in this case, it's a simple edge.  And the red token here needs to go to the blue position, right? So now we have one extra  token inside our graph. But now notice what happens. If any red token wants to come to the  blue position, then this red token needs to be moved to this position before. And if you move  that token up to the blue position, then you can no longer have any of the red tokens on the"
113,00:37:04:840,00:37:40:360," blue position, then this red token needs to be moved to this position before. And if you move  that token up to the blue position, then you can no longer have any of the red tokens on the  universal vertices, which means that they will all have to be simultaneously inside the cliques.  And now we get the behavior that we want. So now we can guarantee that if there is a sequence that  takes the red tokens to the blue position, then some way along that sequence, the tokens are all"
114,00:37:25:240,00:37:58:760," And now we get the behavior that we want. So now we can guarantee that if there is a sequence that  takes the red tokens to the blue position, then some way along that sequence, the tokens are all  going to be within the cliques. Unfortunately, what happened here is we might have introduced  some of the forbidden cycles. We can no longer guarantee that this is C4 up to CP3.  So what you can do in this case to solve this problem, and I'm not going to go into the details,"
115,00:37:45:560,00:38:18:760," some of the forbidden cycles. We can no longer guarantee that this is C4 up to CP3.  So what you can do in this case to solve this problem, and I'm not going to go into the details,  but the intuition should be pretty clear, is that you can subdivide those edges, make them  long enough so that you don't introduce any forbidden cycles, and add appropriate tokens  inside of them to get the same behavior. Because notice that the number of such edges is bounded"
116,00:38:05:960,00:38:39:320," long enough so that you don't introduce any forbidden cycles, and add appropriate tokens  inside of them to get the same behavior. Because notice that the number of such edges is bounded  by a function of K, by a function of, yes, K and P in this case. So you can make these edges,  subdivide them as many times as needed, add as many tokens as needed to maintain all the  properties that we need, and to maintain that we're going from one maximum independent set"
117,00:38:29:080,00:39:10:680," subdivide them as many times as needed, add as many tokens as needed to maintain all the  properties that we need, and to maintain that we're going from one maximum independent set  to the other, which will give you W1 hardness for both token sliding as well as token jumping.  All right. Questions.  No questions. All right. So let's keep going."
118,00:38:48:760,00:39:36:440," All right. Questions.  No questions. All right. So let's keep going.  So now I'm going to talk about some positive results.  So the result that I'm going to talk about is this one here. So I'm going to show you that  on C3, C4-free graphs, token jumping is actually FPG and has a quadratic kernel. But again,"
119,00:39:19:000,00:39:57:960," So the result that I'm going to talk about is this one here. So I'm going to show you that  on C3, C4-free graphs, token jumping is actually FPG and has a quadratic kernel. But again,  what we will show is a stronger result. So what we will show is the following theorem.  What we will show can be summarized as follows. So if you look at any graph  or at any instance of the token jumping problem. So remember, an instance of token jumping has the"
120,00:39:42:680,00:40:20:760," What we will show can be summarized as follows. So if you look at any graph  or at any instance of the token jumping problem. So remember, an instance of token jumping has the  input graph, the starting set, the target set, and K as the number of tokens.  So let me try and draw something here. So if you look at your graph, you can kind of decompose it  into something which is more or less as follows. So you have S, you have T, their intersection"
121,00:40:03:160,00:40:46:279," So let me try and draw something here. So if you look at your graph, you can kind of decompose it  into something which is more or less as follows. So you have S, you have T, their intersection  need not be empty. And then you have the neighborhood of S union T. And then you have  the rest of the graph. So we're going to call the rest of the graph H, and we're going to call  the closed neighborhood of S union T, or if you will, this yellow part here, we call that J."
122,00:40:29:559,00:41:11:000," the rest of the graph. So we're going to call the rest of the graph H, and we're going to call  the closed neighborhood of S union T, or if you will, this yellow part here, we call that J.  So we can think of our problem of our graph as being decomposed into those two areas, H and J.  Okay, so the theorem states the following. If H is epsilon sparse, where epsilon sparse means  that the number of edges is at most n squared minus epsilon, positive epsilon. So if H is"
123,00:40:53:559,00:41:34:680," Okay, so the theorem states the following. If H is epsilon sparse, where epsilon sparse means  that the number of edges is at most n squared minus epsilon, positive epsilon. So if H is  epsilon sparse and J is C3, C4 free, then the problem admits a kernel which is that big,  K squared plus K into one plus one over epsilon.  So notice now that we only need that H is epsilon sparse, and we only require C3, C4"
124,00:41:21:320,00:41:59:720," K squared plus K into one plus one over epsilon.  So notice now that we only need that H is epsilon sparse, and we only require C3, C4  freeness inside J, which is S union T closed neighborhood, closed neighborhood of S union T.  And this idea is actually is not a new idea. So this idea is, okay, I had the drawing here,  I should have used it. So the idea comes from, has been used before, and it's what we call the"
125,00:41:42:280,00:42:18:679," And this idea is actually is not a new idea. So this idea is, okay, I had the drawing here,  I should have used it. So the idea comes from, has been used before, and it's what we call the  buffer technique for the token jumping problem. And the intuition behind the buffer technique is  very simple. So if I have S union T, but somewhere in the graph, which is not in the closed  neighborhood of S union T, I have a K-sized independent set, then you are done, right?"
126,00:42:04:519,00:42:37:559," very simple. So if I have S union T, but somewhere in the graph, which is not in the closed  neighborhood of S union T, I have a K-sized independent set, then you are done, right?  If I have a K-sized independent set in H, then you're done. You can basically  take all the tokens on S, jump them into those independent yellow vertices in H,  and then jump them back to T. So in some sense, when H has a large independent set,"
127,00:42:25:159,00:42:57:400," take all the tokens on S, jump them into those independent yellow vertices in H,  and then jump them back to T. So in some sense, when H has a large independent set,  that's the easy case, right? You're done. If you can find a large enough independent set in H,  you're done. And that's what we call the buffer technique, because it's been also used to show  that the problem is FPT on planar graphs, for example, or K3 J-free graphs, so graphs without"
128,00:42:44:440,00:43:14:599," you're done. And that's what we call the buffer technique, because it's been also used to show  that the problem is FPT on planar graphs, for example, or K3 J-free graphs, so graphs without  large biplanes. So it's a well-known technique. All right.  So what do we show? So we're going to use the buffer technique,  and we're going to combine it with something else."
129,00:43:09:079,00:43:41:000," So what do we show? So we're going to use the buffer technique,  and we're going to combine it with something else.  So we show that you have a yes instance whenever one of those two conditions is true.  The first condition is that H is epsilon sparse and contains more than this many vertices.  And this is relatively easy. When you contain this many vertices and you are epsilon sparse,"
130,00:43:23:720,00:43:54:040," The first condition is that H is epsilon sparse and contains more than this many vertices.  And this is relatively easy. When you contain this many vertices and you are epsilon sparse,  then you will have a K-sized independent set. And that's basically the buffer technique.  When H is epsilon sparse and has that many vertices or more,  then H is guaranteed to have an independent set of size K, and you're done."
131,00:43:46:440,00:44:14:120," When H is epsilon sparse and has that many vertices or more,  then H is guaranteed to have an independent set of size K, and you're done.  So now you are stuck with what happens inside J or the closed neighborhood of S union T.  And it turns out there, if you have C3 C4 freeness, the only thing you need on top of that  to guarantee a yes instance is a vertex of degree at least 3K."
132,00:44:02:600,00:44:38:920," And it turns out there, if you have C3 C4 freeness, the only thing you need on top of that  to guarantee a yes instance is a vertex of degree at least 3K.  So if you have C3 C4 freeness inside J and the vertex of degree 3K, then again,  you get a yes instance. So let me prove those two statements separately,  because they will be basically what we need for the final theorem, for the final kernel."
133,00:44:23:799,00:44:58:119," you get a yes instance. So let me prove those two statements separately,  because they will be basically what we need for the final theorem, for the final kernel.  So the first lemma, as I told you, if H is epsilon sparse and has more than this many vertices,  then it's a yes instance, because you have a K-sized independent set in H.  The idea of this proof is simple. It's a counting argument. And what you need to do basically first"
134,00:44:46:760,00:45:16:519," then it's a yes instance, because you have a K-sized independent set in H.  The idea of this proof is simple. It's a counting argument. And what you need to do basically first  is to show that H must contain a vertex of degree less than N over K. And then basically,  you apply the standard greedy packing algorithm for constructing an independent set of size k.  And the reason you show that and the way you show that H has a vertex of degree less than N over K"
135,00:45:04:679,00:45:37:000," you apply the standard greedy packing algorithm for constructing an independent set of size k.  And the reason you show that and the way you show that H has a vertex of degree less than N over K  is, again, standard counting argument and the handshaking lemma. So if the minimum degree in  H was at least N over K, then the number of edges would be at least N squared over 2K,  which will only happen in an epsilon sparse graph when N is less than or equal to K to the power 1"
136,00:45:23:159,00:45:54:200," H was at least N over K, then the number of edges would be at least N squared over 2K,  which will only happen in an epsilon sparse graph when N is less than or equal to K to the power 1  over epsilon. And the rest of the proof is basically an induction on K.  And so that shows you that when you do have an epsilon sparse graph with more than  this many vertices, then we have a yes instance."
137,00:45:45:480,00:46:18:520," And so that shows you that when you do have an epsilon sparse graph with more than  this many vertices, then we have a yes instance.  All right. So how about the second part of the claim? So now what happens if we have a C3 C4  free J that has a vertex of degree 3K? Well, let's see what happens. So if we have a vertex of degree  3K, and I'm going to circle it here in yellow. So how can the neighborhood of that vertex look?"
138,00:46:03:160,00:46:37:159," free J that has a vertex of degree 3K? Well, let's see what happens. So if we have a vertex of degree  3K, and I'm going to circle it here in yellow. So how can the neighborhood of that vertex look?  Well, we know that J is C3 free. So the blue edges cannot exist,  which means that the neighborhood of the yellow vertex is an independent set inside J,  not in the whole graph. Well, in fact, in the whole, well, no, because we're only talking"
139,00:46:23:880,00:47:03:000," which means that the neighborhood of the yellow vertex is an independent set inside J,  not in the whole graph. Well, in fact, in the whole, well, no, because we're only talking  about J as a subgraph here. Right? So the blue edges cannot exist, because otherwise,  we will get a C3 inside J. All right. So now let's look at the other vertices in S union T.  The second observation that you need is that any vertex other than the yellow vertex can have at"
140,00:46:43:320,00:47:21:720," we will get a C3 inside J. All right. So now let's look at the other vertices in S union T.  The second observation that you need is that any vertex other than the yellow vertex can have at  most one neighbor in common with the yellow vertex. Because if you do have two neighbors in common,  then you will get a C4.  So now what happens if we have 3K vertices in the neighborhood of the yellow vertex? Well,"
141,00:47:10:360,00:47:44:440," then you will get a C4.  So now what happens if we have 3K vertices in the neighborhood of the yellow vertex? Well,  at most 2K of them can be connected to some vertex in S union T, and you will get at least  K of them, some K of them here, that are only connected to the yellow vertex.  And so now basically, instead of using a buffer inside H, we have just found a buffer inside J,"
142,00:47:30:039,00:48:05:640," K of them, some K of them here, that are only connected to the yellow vertex.  And so now basically, instead of using a buffer inside H, we have just found a buffer inside J,  and we can use the same strategy. We can jump all the tokens here,  starting, of course, by the yellow token, and then jump them to where they need to go.  So now combining those two"
143,00:47:50:920,00:48:25:800," starting, of course, by the yellow token, and then jump them to where they need to go.  So now combining those two  observation lemmas together, if you will, we get the following theorem. So if H is alpha sparse,  and J is C3, C4 free, then the problem admits a kernel on this many vertices,  and it's basically a simple application of the previous two lemmas."
144,00:48:15:880,00:48:44:360," and J is C3, C4 free, then the problem admits a kernel on this many vertices,  and it's basically a simple application of the previous two lemmas.  If we have more than this many vertices in H, it's a trivial yes instance. If J has a  vertex of degree 3K or more, it's a trivial yes instance. And now you combine all of this together.  We know that S union T is of size at most 2K. We know that the neighborhood of S union T is"
145,00:48:31:880,00:49:12:280," vertex of degree 3K or more, it's a trivial yes instance. And now you combine all of this together.  We know that S union T is of size at most 2K. We know that the neighborhood of S union T is  of size at most 2K times 3K, which is roughly 6K squared. And now we know that the rest of the  graph has at most that many vertices. So basically you sum up those numbers, and you get this bound.  All right. So how does this theorem imply the result that I promised you to start with?"
146,00:48:50:920,00:49:37:080," graph has at most that many vertices. So basically you sum up those numbers, and you get this bound.  All right. So how does this theorem imply the result that I promised you to start with?  So that token jumping and token sliding admit a kernel with order K square vertices,  I mean, it also holds for bipartite C4 free graphs, right? Obviously because they are C3,  C4 free. So how do you get the kernel? Well, we know that J cannot contain more than 6K"
147,00:49:23:720,00:49:57:480," I mean, it also holds for bipartite C4 free graphs, right? Obviously because they are C3,  C4 free. So how do you get the kernel? Well, we know that J cannot contain more than 6K  squared minus 2K vertices. And we know from another theorem, from another  paper that C3 free graphs with K squared over log K vertices must have an independent set of size  at least K. And now we know that if H contains more than this many vertices, then we will get"
148,00:49:44:199,00:50:12:680," paper that C3 free graphs with K squared over log K vertices must have an independent set of size  at least K. And now we know that if H contains more than this many vertices, then we will get  the yes instance as well. Right? So it becomes an immediate consequence of the previous theorem.  But the previous theorem is even more general than this corollary. So this corollary  does not really use the full power of this theorem."
149,00:50:05:800,00:50:39:160," But the previous theorem is even more general than this corollary. So this corollary  does not really use the full power of this theorem.  All right. That's it. I think I'm on time. If you have questions, I will take them now.  It was 55 minutes, right? For the talk. I did not go under the time.  It's fine. We usually allow plus minus 10 minutes. That's all right."
150,00:50:23:240,00:51:01:320," It was 55 minutes, right? For the talk. I did not go under the time.  It's fine. We usually allow plus minus 10 minutes. That's all right.  So I have a question about token sliding. Yes.  So how crucial, what happens if one does not restrict the independent sets during the  configuration to be not of the same size? Is that very critical for the difficulty"
151,00:50:46:920,00:51:15:719," So how crucial, what happens if one does not restrict the independent sets during the  configuration to be not of the same size? Is that very critical for the difficulty  or the easiness of the problem? Well, you have to be careful how  you define that because in token sliding, sliding tokens cannot leave the graph.  That's correct. But the independent set sequence,"
152,00:51:06:280,00:51:31:719," you define that because in token sliding, sliding tokens cannot leave the graph.  That's correct. But the independent set sequence,  all the independent sets have to be the same size, right?  Well, if not some token disappeared at some point and I'm not sure how it disappeared.  Right? Because you start with something of size K and you're going to something of size K,"
153,00:51:19:159,00:51:53:000," Well, if not some token disappeared at some point and I'm not sure how it disappeared.  Right? Because you start with something of size K and you're going to something of size K,  you cannot leave the graph unless you define it in some way. So you will remain of size K throughout.  But you can become slightly larger than K. But where does the new token come from?  So there is a third rule that I did not tell you about,"
154,00:51:41:159,00:52:14:679," But you can become slightly larger than K. But where does the new token come from?  So there is a third rule that I did not tell you about,  which is called token addition and removal. Under that rule, we actually allow you to  remove vertices and add vertices as long as you remain an independent set of size at least K.  Does that answer your question? Yeah, yeah, yeah, yeah, yeah."
155,00:52:00:199,00:52:30:599," remove vertices and add vertices as long as you remain an independent set of size at least K.  Does that answer your question? Yeah, yeah, yeah, yeah, yeah.  But in fact, it was shown that this, it was shown that, so addition and removal is  equivalent to token jumping. I see, I see.  Right? It doesn't, it never makes sense to add more tokens to your graph if you don't need them."
156,00:52:22:440,00:52:54:599," equivalent to token jumping. I see, I see.  Right? It doesn't, it never makes sense to add more tokens to your graph if you don't need them.  You're only making your life harder, intuitively speaking.  So the other question that I had is, I mean, I heard,  so is it possible to view this whole problem on an exponential size graph where every vertex"
157,00:52:41:079,00:53:13:960," So the other question that I had is, I mean, I heard,  so is it possible to view this whole problem on an exponential size graph where every vertex  corresponds to an independent set in the original graph? And then you have edges between  two vertices if there is an edge between two vertices of the independent set.  And now you are doing a reachability question. Is that a meaningful way to think about this?"
158,00:53:03:159,00:53:29:400," two vertices if there is an edge between two vertices of the independent set.  And now you are doing a reachability question. Is that a meaningful way to think about this?  But that's exactly what we're doing. So the way you define your adjacency, I think,  so you mean you define, you make two independent sets adjacent if one can be reached from the  other via a single slide or a single jump. Exactly, yeah, one edge, yeah. There is"
159,00:53:19:960,00:53:47:079," so you mean you define, you make two independent sets adjacent if one can be reached from the  other via a single slide or a single jump. Exactly, yeah, one edge, yeah. There is  one pair, u and v, which is adjacent. But that's exactly what we're doing.  OK, OK, yeah. I mean, because we're looking at algorithms here, we kind of forget the  structural picture behind it. But this algorithm is finding a path in this graph that you're"
160,00:53:34:519,00:54:16:920," OK, OK, yeah. I mean, because we're looking at algorithms here, we kind of forget the  structural picture behind it. But this algorithm is finding a path in this graph that you're  describing. Yeah, yeah, that's right. And what we're saying is you can do it in FPT time or not,  depending on the problem we're talking about. Hi, Amir.  How are you? Yeah, I'm good. So I have a question. So do the problems remain equally"
161,00:53:54:039,00:54:31:880," depending on the problem we're talking about. Hi, Amir.  How are you? Yeah, I'm good. So I have a question. So do the problems remain equally  hard if we bound the if we have a restriction on the number of times  we can move the token to a particular vertex?  The number of times you can move a token to a particular vertex."
162,00:54:21:240,00:54:49:800," we can move the token to a particular vertex?  The number of times you can move a token to a particular vertex.  Like the number of times the tokens can be moved to a vertex.  Well, that's definitely going to change the complexity in at least intuitively speaking,  because now you're saying maybe it will if you're bounding that by a constant,"
163,00:54:38:360,00:55:09:400," Well, that's definitely going to change the complexity in at least intuitively speaking,  because now you're saying maybe it will if you're bounding that by a constant,  then you might be saying that I'm not allowing exponentially large sequences anymore.  But in terms of exactly how the complexity changes, I don't have answers. I think it's a  very nice question to pose. Even in terms of nonparameterized complexity, standard complexity,"
164,00:54:55:400,00:55:22:680," But in terms of exactly how the complexity changes, I don't have answers. I think it's a  very nice question to pose. Even in terms of nonparameterized complexity, standard complexity,  I think that that would be a very interesting question, because  because it will definitely affect the behavior. I'm not sure exactly how yet.  I don't know of any results that ask this particular question."
165,00:55:13:240,00:55:42:039," because it will definitely affect the behavior. I'm not sure exactly how yet.  I don't know of any results that ask this particular question.  Okay, so I had one more question in the W-hardness result that you presented.  So do you know like the length of the the the length of the changes are actually the  number of changes or flips that you make in your independent set? This is just."
166,00:55:29:079,00:55:59:880," So do you know like the length of the the the length of the changes are actually the  number of changes or flips that you make in your independent set? This is just.  Yes, yes, yes. We do. So here the number of changes is going to be very it's it's  basically going to be the shortest possible sequence. So it's it's going to it's it's  basically going to be so if you think about the simple construction, this one."
167,00:55:49:000,00:56:18:599," basically going to be the shortest possible sequence. So it's it's going to it's it's  basically going to be so if you think about the simple construction, this one.  It's basically literally going to be these guys are going to move here. So each is going to cost  me one slide and then they're all going to and now this guy is going to move here. And now I will pay  one slide for each one here. Now this is the simplified version of it. Once you go to the"
168,00:56:05:559,00:56:42:039," me one slide and then they're all going to and now this guy is going to move here. And now I will pay  one slide for each one here. Now this is the simplified version of it. Once you go to the  complete version of it, you have some extra slides within the path, but you can also count those.  Okay, so but does this mean that so does this mean that at a particular vertex, we're  placing the token at most once? In this case, yes. Okay. In this case, yes. Okay. So this problem"
169,00:56:23:960,00:57:02:680," Okay, so but does this mean that so does this mean that at a particular vertex, we're  placing the token at most once? In this case, yes. Okay. In this case, yes. Okay. So this problem  should be hard, even if we bound the number of times tokens can be moved to a vertex, right?  Should be hard, even if we bound the number of times tokens can be moved to a vertex, right?  Yes. Okay. Yes. So so here in this case, yes. Absolutely. Okay. Thanks."
170,00:56:47:400,00:57:25:480," Should be hard, even if we bound the number of times tokens can be moved to a vertex, right?  Yes. Okay. Yes. So so here in this case, yes. Absolutely. Okay. Thanks.  So Akanksha, I have a remark about your question. So if a vertex, if a vertex cannot get a token  twice, then it somehow seems to be selecting disjoint independent sets,  a sequence of them, and that may have some bearing on coloring, just a top level."
171,00:57:12:920,00:57:49:320," twice, then it somehow seems to be selecting disjoint independent sets,  a sequence of them, and that may have some bearing on coloring, just a top level.  So actually, for the list, the W harness case that I'm in presented, it is exactly the case,  right? So we are not allowed to move the token, like twice on the same vertex.  Yeah. So I didn't get your point of moving. So getting this disjoint independence, it's actually"
172,00:57:35:960,00:58:08:280," right? So we are not allowed to move the token, like twice on the same vertex.  Yeah. So I didn't get your point of moving. So getting this disjoint independence, it's actually  because if you say if you think of it from my the way I thought about it, right, that you are  actually trying to find a path in a large graph where every vertex corresponds to an independent  set, and you move from one independent set to another. So we can only move from one independent"
173,00:57:55:159,00:58:28:519," actually trying to find a path in a large graph where every vertex corresponds to an independent  set, and you move from one independent set to another. So we can only move from one independent  set to the other, if the changes is like in case of tokens sliding, it's one probably.  Yeah.  So it looks to me that you're asking for a collection of independent sets,"
174,00:58:17:400,00:58:48:680," Yeah.  So it looks to me that you're asking for a collection of independent sets,  which are vertex disjoint, if the token sequence of independent sets which are vertex disjoint.  Yeah. So if I may, I think Akansha's question would be more relevant in a place where we don't  have a monotone sequence, meaning a sequence. So we need a version of the problem or some cases of"
175,00:58:34:840,00:59:08:360," Yeah. So if I may, I think Akansha's question would be more relevant in a place where we don't  have a monotone sequence, meaning a sequence. So we need a version of the problem or some cases of  the problem where a vertex has to be visited multiple times to find solutions. And that is  known to be the case for some versions or some statements of the problem. And in fact, Akansha,  so this was the crucial difference between PSPACE completeness and NP completeness of sliding versus"
176,00:58:55:160,00:59:31:720," known to be the case for some versions or some statements of the problem. And in fact, Akansha,  so this was the crucial difference between PSPACE completeness and NP completeness of sliding versus  jumping in bipartite graphs. So it was because we were able to show that no vertex will be visited  more than once in the other problems. So that's why it's definitely an interesting question to  pose, but you have to be careful in what context you pose it. I don't know if that kind of settles"
177,00:59:15:080,01:00:20:360," more than once in the other problems. So that's why it's definitely an interesting question to  pose, but you have to be careful in what context you pose it. I don't know if that kind of settles  answers your question. Yes, yes, it does. All right. Thanks. You're welcome.  Any more questions?  I guess not."
178,00:59:39:079,01:00:38:679," Any more questions?  I guess not.  Yeah, I don't think there are any more questions. I will just once again announce the parameterized  algorithm 301 workshop, which is going to happen in December. And the link has been posted once  again in the chat. Some advanced topics in parameterized complexity will be discussed."
179,01:00:27:400,01:01:15:000," algorithm 301 workshop, which is going to happen in December. And the link has been posted once  again in the chat. Some advanced topics in parameterized complexity will be discussed.  Those interested can have a look and register for it.  And yeah, if there are any more questions, please ask away.  Oh, so anyone can register for the"
180,01:00:43:640,01:01:30:360," And yeah, if there are any more questions, please ask away.  Oh, so anyone can register for the  school? Yes, yes, anyone can.  Yeah, it's free and it's online and yeah, it's open to everyone.  Awesome. So I can share it with my students as well."
181,01:01:23:400,01:01:46:680," Yeah, it's free and it's online and yeah, it's open to everyone.  Awesome. So I can share it with my students as well.  Of course, of course, please do. Yeah, that would be good. And we assumed some basic  understanding of parameterized algorithms, but we have already shared a link on the page  where students can go and go through some previous lectures in parameterized algorithms if"
182,01:01:34:920,01:02:10:920," understanding of parameterized algorithms, but we have already shared a link on the page  where students can go and go through some previous lectures in parameterized algorithms if  they wish to just brace up or revise stuff.  All right, so I guess, okay, I don't think there are any more questions.  So maybe this is a good time to wrap up. So thank you once again Professor Amedoh for"
183,01:01:57:639,01:02:27:000," All right, so I guess, okay, I don't think there are any more questions.  So maybe this is a good time to wrap up. So thank you once again Professor Amedoh for  agreeing to give the talk. It was really nice to have you and it was really good to have something  different than what we usually hear in every parameterized complexity talk, at least most  of them. So and yeah, these are really interesting problems to think upon. And thank you to the"
